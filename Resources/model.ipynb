{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thoma\\AppData\\Local\\Temp\\ipykernel_27492\\2028436544.py:29: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Time'] = pd.to_datetime(data['Time'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thoma\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.7750 - loss: 0.5382 - val_accuracy: 0.7747 - val_loss: 0.5342\n",
      "Epoch 2/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7790 - loss: 0.5286 - val_accuracy: 0.7766 - val_loss: 0.5003\n",
      "Epoch 3/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7891 - loss: 0.5029 - val_accuracy: 0.8192 - val_loss: 0.4650\n",
      "Epoch 4/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8078 - loss: 0.4806 - val_accuracy: 0.8223 - val_loss: 0.4617\n",
      "Epoch 5/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8106 - loss: 0.4779 - val_accuracy: 0.8028 - val_loss: 0.4864\n",
      "Epoch 6/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8135 - loss: 0.4733 - val_accuracy: 0.8160 - val_loss: 0.4706\n",
      "Epoch 7/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.4714 - val_accuracy: 0.8164 - val_loss: 0.4703\n",
      "Epoch 8/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.4717 - val_accuracy: 0.8229 - val_loss: 0.4627\n",
      "Epoch 9/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8174 - loss: 0.4700 - val_accuracy: 0.8237 - val_loss: 0.4616\n",
      "Epoch 10/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8197 - loss: 0.4667 - val_accuracy: 0.8212 - val_loss: 0.4650\n",
      "Epoch 11/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8183 - loss: 0.4689 - val_accuracy: 0.8229 - val_loss: 0.4634\n",
      "Epoch 12/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8204 - loss: 0.4663 - val_accuracy: 0.8286 - val_loss: 0.4576\n",
      "Epoch 13/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8206 - loss: 0.4648 - val_accuracy: 0.8180 - val_loss: 0.4713\n",
      "Epoch 14/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.4631 - val_accuracy: 0.8170 - val_loss: 0.4719\n",
      "Epoch 15/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.4674 - val_accuracy: 0.8230 - val_loss: 0.4630\n",
      "Epoch 16/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8212 - loss: 0.4650 - val_accuracy: 0.8297 - val_loss: 0.4580\n",
      "Epoch 17/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8183 - loss: 0.4686 - val_accuracy: 0.8265 - val_loss: 0.4580\n",
      "Epoch 18/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8197 - loss: 0.4673 - val_accuracy: 0.8270 - val_loss: 0.4577\n",
      "Epoch 19/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8216 - loss: 0.4634 - val_accuracy: 0.8248 - val_loss: 0.4601\n",
      "Epoch 20/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.4634 - val_accuracy: 0.8218 - val_loss: 0.4664\n",
      "Epoch 21/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8220 - loss: 0.4644 - val_accuracy: 0.8284 - val_loss: 0.4562\n",
      "Epoch 22/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8226 - loss: 0.4621 - val_accuracy: 0.8260 - val_loss: 0.4592\n",
      "Epoch 23/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8227 - loss: 0.4630 - val_accuracy: 0.8261 - val_loss: 0.4591\n",
      "Epoch 24/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8204 - loss: 0.4654 - val_accuracy: 0.8235 - val_loss: 0.4631\n",
      "Epoch 25/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.4629 - val_accuracy: 0.8217 - val_loss: 0.4662\n",
      "Epoch 26/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.4621 - val_accuracy: 0.8037 - val_loss: 0.4930\n",
      "Epoch 27/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8240 - loss: 0.4609 - val_accuracy: 0.8241 - val_loss: 0.4628\n",
      "Epoch 28/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8228 - loss: 0.4626 - val_accuracy: 0.8273 - val_loss: 0.4588\n",
      "Epoch 29/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.4593 - val_accuracy: 0.8233 - val_loss: 0.4629\n",
      "Epoch 30/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8217 - loss: 0.4650 - val_accuracy: 0.8248 - val_loss: 0.4606\n",
      "Epoch 31/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8239 - loss: 0.4622 - val_accuracy: 0.8281 - val_loss: 0.4565\n",
      "Epoch 32/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8233 - loss: 0.4626 - val_accuracy: 0.8267 - val_loss: 0.4581\n",
      "Epoch 33/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8235 - loss: 0.4627 - val_accuracy: 0.8251 - val_loss: 0.4605\n",
      "Epoch 34/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8243 - loss: 0.4610 - val_accuracy: 0.8218 - val_loss: 0.4652\n",
      "Epoch 35/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.8239 - loss: 0.4622 - val_accuracy: 0.8288 - val_loss: 0.4555\n",
      "Epoch 36/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8239 - loss: 0.4623 - val_accuracy: 0.8251 - val_loss: 0.4605\n",
      "Epoch 37/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.8251 - loss: 0.4596 - val_accuracy: 0.8263 - val_loss: 0.4586\n",
      "Epoch 38/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8262 - loss: 0.4584 - val_accuracy: 0.8297 - val_loss: 0.4562\n",
      "Epoch 39/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.4587 - val_accuracy: 0.8228 - val_loss: 0.4640\n",
      "Epoch 40/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.4601 - val_accuracy: 0.8255 - val_loss: 0.4598\n",
      "Epoch 41/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8245 - loss: 0.4609 - val_accuracy: 0.8234 - val_loss: 0.4638\n",
      "Epoch 42/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8240 - loss: 0.4610 - val_accuracy: 0.8299 - val_loss: 0.4563\n",
      "Epoch 43/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.4559 - val_accuracy: 0.8201 - val_loss: 0.4686\n",
      "Epoch 44/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8256 - loss: 0.4599 - val_accuracy: 0.8281 - val_loss: 0.4566\n",
      "Epoch 45/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8259 - loss: 0.4589 - val_accuracy: 0.8257 - val_loss: 0.4600\n",
      "Epoch 46/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.4596 - val_accuracy: 0.8233 - val_loss: 0.4652\n",
      "Epoch 47/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8245 - loss: 0.4611 - val_accuracy: 0.8296 - val_loss: 0.4565\n",
      "Epoch 48/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8259 - loss: 0.4586 - val_accuracy: 0.8173 - val_loss: 0.4725\n",
      "Epoch 49/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8240 - loss: 0.4613 - val_accuracy: 0.8286 - val_loss: 0.4568\n",
      "Epoch 50/50\n",
      "\u001b[1m3833/3833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.4597 - val_accuracy: 0.8231 - val_loss: 0.4639\n",
      "\u001b[1m959/959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8290 - loss: 0.4556\n",
      "Test Loss: 0.4555196166038513, Test Accuracy: 0.8288490772247314\n",
      "\u001b[1m959/959\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90     23754\n",
      "           1       0.79      0.33      0.46      6909\n",
      "\n",
      "    accuracy                           0.83     30663\n",
      "   macro avg       0.81      0.65      0.68     30663\n",
      "weighted avg       0.82      0.83      0.80     30663\n",
      "\n",
      "AUC: 0.65110034168069\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "#This is for the RNN Model.\n",
    "\n",
    "# Load the transaction dataset\n",
    "data = pd.read_csv('mock_transactions.csv')\n",
    "\n",
    "# Preprocessing the dataset\n",
    "# Selecting relevant columns for RNN training\n",
    "features = ['Amount', 'City', 'State', 'Latitude', 'Longitude', 'Time']\n",
    "target = 'Is Fraud?'\n",
    "\n",
    "# Encode categorical columns (City and State)\n",
    "label_encoders = {}\n",
    "for col in ['City', 'State']:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Extract time-based features (hour, day of week, etc.)\n",
    "data['Time'] = pd.to_datetime(data['Time'])\n",
    "data['Hour'] = data['Time'].dt.hour\n",
    "data['DayOfWeek'] = data['Time'].dt.dayofweek\n",
    "data['Day'] = data['Time'].dt.day\n",
    "\n",
    "# Update features list to include new time-based features\n",
    "features = ['Amount', 'City', 'State', 'Latitude', 'Longitude', 'Hour', 'DayOfWeek', 'Day']\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = MinMaxScaler()\n",
    "data[['Amount', 'Latitude', 'Longitude', 'Hour', 'DayOfWeek', 'Day']] = scaler.fit_transform(\n",
    "    data[['Amount', 'Latitude', 'Longitude', 'Hour', 'DayOfWeek', 'Day']]\n",
    ")\n",
    "\n",
    "# Create feature and target arrays\n",
    "X = data[features].values\n",
    "y = data[target].values\n",
    "\n",
    "# Reshape target for compatibility\n",
    "y = np.reshape(y, (-1, 1))\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data for LSTM (samples, timesteps, features)\n",
    "# Assuming each transaction is independent (timesteps=1)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Building the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=64, activation='relu'))  # Hidden dense layer\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # Output layer\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Add EarlyStopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = (model.predict(X_test) > 0.5)\n",
    "\n",
    "# Print classification report and AUC\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"AUC: {roc_auc_score(y_test, y_pred)}\")\n",
    "\n",
    "# Save the model\n",
    "model.save('fraud_detection_rnn.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "Best Hyperparameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thoma\\AppData\\Local\\Temp\\ipykernel_27492\\1729007157.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Time'] = pd.to_datetime(data['Time'])\n",
      "C:\\Users\\Thoma\\AppData\\Local\\Temp\\ipykernel_27492\\1729007157.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['Amount', 'Latitude', 'Longitude']] = scaler.fit_transform(X[['Amount', 'Latitude', 'Longitude']])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     27243\n",
      "           1       0.38      0.05      0.08      3446\n",
      "\n",
      "    accuracy                           0.88     30689\n",
      "   macro avg       0.64      0.52      0.51     30689\n",
      "weighted avg       0.83      0.88      0.84     30689\n",
      "\n",
      "AUC: 0.5185518431960637\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#This is for the Random Forest Model\n",
    "\n",
    "# Define hyperparameters grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Apply GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Use best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('mock_transactions.csv')\n",
    "\n",
    "# Drop sensitive features\n",
    "data = data.drop(['Card Number', 'CVV', 'Expires'], axis=1)\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in ['Errors?', 'Has Chip', 'City', 'State']:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Extract time-based features from 'Time'\n",
    "data['Time'] = pd.to_datetime(data['Time'])\n",
    "data['Hour'] = data['Time'].dt.hour\n",
    "data['DayOfWeek'] = data['Time'].dt.dayofweek\n",
    "data['Day'] = data['Time'].dt.day\n",
    "\n",
    "# Update feature list\n",
    "features = ['Amount', 'Errors?', 'Use Chip', 'Has Chip', 'City', 'State', 'Latitude', 'Longitude', 'Hour', 'DayOfWeek', 'Day']\n",
    "target = 'Is Fraud?'\n",
    "\n",
    "# Separate features and target\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[['Amount', 'Latitude', 'Longitude']] = scaler.fit_transform(X[['Amount', 'Latitude', 'Longitude']])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"AUC: {roc_auc_score(y_test, y_pred)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
